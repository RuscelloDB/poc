# application logs
application-logs = "/var/log/ruscello"

# Raft RuscolloConfiguration
[raft]
# The raft port should be open between all servers in a cluster.
# However, this port shouldn't be accessible from the internet.
port = 8090

# Where the raft logs are stored. The user running Ruscello will need read/write access.
dir  = "/opt/ruscello/shared/data/raft"

debug = false


# storage engine settings
[storage]
# TODO: where do we want to store data by default?
dir = "/var/lib/ruscello/"

# TODO: what should be the default and what should be call this setting?
# TODO: should we use fully qualified name? That way the logic wont need to change for each new storage engine?
#       although that should just really be updating a case statement so thats not toooo bad
# Possible values: lmdb, rocksdb and maybe filesystem, memory
default-engine = "rocksdb"



[storage.engines.rocksdb]

# LRU cache size, LRU is used by rocksdb to store contents of the
# uncompressed sstables. You can use `m` or `g` prefix for megabytes and gigabytes, respectively.
lru-cache-size = "200m"

  [dbOptions]
  create-if-missing = true

  # This specifies the info LOG dir.
  # If it is empty, the log files will be in the same dir as data.
  # If it is non empty, the log files will be in the specified dir,
  # and the db data dir's absolute path will be used as the log file
  # name's prefix.
  dbLogDir = ""

  # The periodicity when obsolete files get deleted. The default
  # value is 6 hours. The files that get out of scope by compaction
  # process will still get automatically delete on every compaction,
  # regardless of this setting
  # deleteObsoleteFilesPeriodMicros = ""


  # A list of paths where SST files can be put into, with its target size.
  # Newer data is placed into paths specified earlier in the vector while
  # older data gradually moves to paths specified later in the vector.
  # For example, you have a flash device with 10GB allocated for the DB,
  # as well as a hard drive of 2TB, you should config it to be:
  #    [{"/flash_path", 10GB}, {"/hard_drive", 2TB}]
  # The system will try to guarantee data under each path is close to but
  # not larger than the target size. But current and future file sizes used
  # by determining where to place a file are based on best-effort estimation,
  # which means there is a chance that the actual size under the directory
  # is slightly more than target size under some workloads. User should give
  # some buffer room for those cases.
  # If none of the paths has sufficient room to place a file, the file will
  # be placed to the last path anyway, despite to the target size.
  # Placing newer data to earlier paths is also best-efforts. User should
  # expect user files to be placed in higher levels in some extreme cases.
  # If left empty, only one path will be used, which is db_name passed when
  # opening the DB.
  # Default: empty
  # dbPaths = ""

  # Amount of data to build up in memtables across all column
  # families before writing to disk.
  # This is distinct from ColumnFamilyOptions writeBufferSize,
  # which enforces a limit for a single memtable.
  # This feature is disabled by default. Specify a non-zero value
  # to enable it.
  # Default: 0 (disabled)
  # dbWriteBufferSize = 0

  # If true, then DB::Open / CreateColumnFamily / DropColumnFamily SetOptions
  # will fail if options file is not detected or properly persisted.
  # failIfOptionsFileError = false

  # TODO: should this go up to the application log setting? What does LMDB provide?
  # LMDB doesn't look like they provide anything
  # Specifies the maximum number of info log files to be kept.
  # Default: 1000
  # keepLogFileName = 1000

  # Specifies the time interval for the info log file to roll (in seconds).
  # If specified with non-zero value, log file will be rolled
  # if it has been active longer than `log_file_time_to_roll`.
  # Default: 0 (disabled)
  # logFileTimeToRoll = 0

  # Specifies the maximum size of a info log file. If the current log file
  # is larger than `max_log_file_size`, a new info log file will be created.
  # If 0, all logs will be written to one log file.
  maxLogFileSize = 0

  # Recycle log files.
  # If non-zero, we will reuse previously written log files for new
  # logs, overwriting the old data.  The value indicates how many
  # such files we will keep around at any point in time for later use.
  # This is more efficient because the blocks are already
  # allocated and fdatasync does not need to update the inode after
  # each write.
  # Default: 0
  # recycleLogFileNum = 0

  # Sets the RocksDB log level. Default level is INFO
  # infoLogLevel = "INFO"

  # If is -1, DB will open all files on db open.
  # You can use this option to increase the number of threads used to open the files.
  # Default: 16
  # maxFileOpeningThreads = 16


  # Number of open files that can be used by the DB.  You may need to
  # increase this if your database has a large working set. Value -1 means
  # files opened are always kept open. You can estimate number of files based
  # on target_file_size_base target_file_size_multiplier for level-based compaction.
  # For universal-style compaction, you can usually set it to -1.
  # Default: 5000
  # Maximum mmap open files, this will affect the virtual memory used by
  # the process
  # max-open-files = 5000


  # By default, RocksDB uses only one background thread for flush and compaction.
  # Will set it up such that total of total_threads is used
  # You almost definitely want to call this function if your system is
  # bottlenecked by RocksDB.
  # The total number of threads to be used by RocksDB.
  # good value is the number of cores.
  # this is the recommended way to increase parallelism in RocksDb
  # note that the current implementation of setIncreaseParallelism affects the number
  # of compaction threads but not flush threads (the latter remains one). Also
  # the parallelism value needs to be at least two because of the code in
  # https://github.com/facebook/rocksdb/blob/62ad0a9b19f0be4cefa70b6b32876e764b7f3c11/util/options.cc#L580
  # subtracts one from the value passed to determine the number of compaction threads
  # (this could be a bug in the RocksDB code and their devs have been contacted).
  # Default will be number of A) number of available processors B) 2
  # setIncreaseParallelism = ""

  # Suggested number of concurrent background compaction jobs, submitted to the default LOW priority thread pool.
  # Default: 1
  # baseBackgroundCompactions


  # Specifies the maximum number of concurrent background compaction jobs, submitted to the default LOW priority thread pool.
  # If you're increasing this, also consider increasing number of threads in LOW priority thread pool.
  # The default is 1, but to fully utilize your CPU and storage you might want to increase this to approximately number of cores in the system.
  # maxBackgroundCompactions


  # Returns the maximum number of concurrent background flush jobs.
  # If you're increasing this, also consider increasing number of threads in HIGH priority thread pool.
  # is the maximum number of concurrent flush operations. It is usually good enough to set this to 1.
  # Default: 1
  # maxBackgroundFlushes


  # column family options
  [cfOptions]


  # Compress blocks using the specified compression algorithm.
  # Possible values: NO_COMPRESSION, SNAPPY_COMPRESSION, ZLIB_COMPRESSION, BZLIB2_COMPRESSION, LZ4_COMPRESSION,
  # LZ4HC_COMPRESSION, XPRESS_COMPRESSION, ZSTD_COMPRESSION, DISABLE_COMPRESSION_OPTION
  # Apache kafka streams defaults to NO_COMPRESSION
  # Default: SNAPPY_COMPRESSION, which gives lightweight but fast compression.
  # compressionType = "SNAPPY_COMPRESSION"

  # Set compaction style for DB.
  # LEVEL - Level based Compaction style
  # UNIVERSAL - Universal Compaction Style is a compaction style, targeting the use cases requiring lower write
  #             amplification, trading off read amplification and space amplification.
  # FIFO - FIFO compaction style is the simplest compaction strategy. It is suited for keeping event log data with
  # very low overhead (query log for example). It periodically deletes the old data, so it's basically a TTL compaction style
  # Apache Kafka Streams default to UNIVERSAL however rocksdb warns about using this with a large > 100GB database
  # Default: LEVEL.
  # compationStyle = "LEVEL"


  # Amount of data to build up in memory (backed by an unsorted log on disk) before converting to a sorted on-disk file.
  # Larger values increase performance, especially during bulk loads.
  # Up to max_write_buffer_number write buffers may be held in memory at the same time, so you may wish to adjust this parameter
  # to control memory usage. Also, a larger write buffer will result in a longer recovery time the next time the database is opened.
  # Default: 4MB
  # writeBufferSize: "4MB"


  # The maximum number of write buffers that are built up in memory.
  # The default is 2, so that when 1 write buffer is being flushed to storage, new writes can continue to the other write buffer.
  # Default: 2
  # max_write_buffer_number: 2

  # Flush Options
  [fOptions]

  # Set if the flush operation shall block until it terminates.
  # DEFAULT: false
  # Apache Kafka Streams sets this to true
  # waitForFlush = false



[storage.engines.lmdb]

    # Sets the size of the memory map to use for the environment
    # The size should be a multiple of the OS page size. The default is 10485760 bytes.
    # The size of the memory maps is also the maximum size of the datagbase.
    # The value should be chosen as large as possible, to accomodate for future growth of the database.
    map-size = "100g"

    # TODO: do we want to expose this? If we did how would we utilize it?
    # LMDB docs say this defaults to 126 however lmdbjava appears to default to 1
    # TODO: open issue on github asking about this
    # Sets the maximum number of threads/reader slots for the environment
    # The default is 126. Starting a read-only transaction normally ties a lock table slot to the current thread until the environment closes or the thread exits.
    # Defaults to 126
    # max-readers = 126